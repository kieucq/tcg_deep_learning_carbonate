{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "80518cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# NOTE: This machine learning program is for predicting TC formation, using\n",
    "#       input dataset in the NETCDF format. The program treats different\n",
    "#       2D input fields as different channels of an image. This specific\n",
    "#       program requires a set of 12 2D-variables (12-channel image) and\n",
    "#       consists of three stages\n",
    "#       - Stage 1: reading NETCDF input and generating (X,y) data with a\n",
    "#                  given image sizes, which are then saved by pickle;\n",
    "#       - Stage 2: import the saved pickle (X,y) pair and build a CNN model\n",
    "#                  with a given training/validation ratio, and then save\n",
    "#                  the train model under tcg_CNN.model.\n",
    "#       - Stage 3: import the trained model from Stage 2, and make a list\n",
    "#                  of prediction from normalized test data.\n",
    "#\n",
    "# INPUT: This Stage 3 script reads in the CNN trained model \"tcg_CNN.model\"\n",
    "#        that is generated from Step 2.\n",
    "#\n",
    "#        Remarks: Note that the input data for this script must be on the\n",
    "#        same as in Step 1 with standard 19 vertical\n",
    "#        levels 1000, 975, 950, 925, 900, 850, 800, 750, 700, 650, 600,\n",
    "#        550, 500, 450, 400, 350, 300, 250, 200. Also, all field vars must\n",
    "#        be resize to cover an area of 30x30 around the TC center for the\n",
    "#        positive data cases.\n",
    "#        Similar to Step 2, this Step 3 needs to also have a large mem\n",
    "#        allocation so that it can be run properly.\n",
    "#\n",
    "# OUTPUT: A list of probability forecast with the same dimension as the\n",
    "#        number of input 12-channel images.\n",
    "#\n",
    "# HIST: - 01, Nov 22: Created by CK\n",
    "#       - 02, Nov 22: Modified to optimize it\n",
    "#       - 05. Jun 23: Rechecked and added F1 score function for a list of models\n",
    "#\n",
    "# AUTH: Chanh Kieu (Indiana University, Bloomington. Email: ckieu@iu.edu)\n",
    "#\n",
    "#==========================================================================\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import netCDF4\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "70d857fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Function to return input data as an numpy array\n",
    "#\n",
    "def prepare(filepath):\n",
    "    IMG_SIZE_X = 128\n",
    "    IMG_SIZE_Y = 64\n",
    "    number_channels = 12\n",
    "    f = netCDF4.Dataset(filepath)\n",
    "    abv = f.variables['absvprs']\n",
    "    nx = f.dimensions['lon'].size\n",
    "    ny = f.dimensions['lat'].size\n",
    "    nz = f.dimensions['lev'].size\n",
    "    a2 = np.zeros((nx,ny,number_channels))\n",
    "    for i in range(a2.shape[0]):\n",
    "        for j in range(a2.shape[1]):\n",
    "            a2[i,j,0] = abv[1,j,i]    # abs vort at 950 mb\n",
    "    rel = f.variables['rhprs']\n",
    "    for i in range(a2.shape[0]):\n",
    "        for j in range(a2.shape[1]):\n",
    "            a2[i,j,1] = rel[7,j,i]    # RH at 750 mb\n",
    "    sfc = f.variables['pressfc']\n",
    "    for i in range(a2.shape[0]):\n",
    "        for j in range(a2.shape[1]):\n",
    "            a2[i,j,2] = sfc[j,i]      # surface pressure\n",
    "    tmp = f.variables['tmpprs']\n",
    "    for i in range(a2.shape[0]):\n",
    "        for j in range(a2.shape[1]):\n",
    "            a2[i,j,3] = tmp[15,j,i]   # temperature at 400 mb\n",
    "    tsf = f.variables['tmpsfc']\n",
    "    for i in range(a2.shape[0]):\n",
    "        for j in range(a2.shape[1]):\n",
    "            a2[i,j,4] = tsf[j,i]      # surface temperature\n",
    "    ugr = f.variables['ugrdprs']\n",
    "    for i in range(a2.shape[0]):\n",
    "        for j in range(a2.shape[1]):\n",
    "            a2[i,j,5] = ugr[3,j,i]    # u-wind at 900 mb\n",
    "            a2[i,j,6] = ugr[17,j,i]   # u-wind at 300 mb\n",
    "    vgr = f.variables['vgrdprs']\n",
    "    for i in range(a2.shape[0]):\n",
    "        for j in range(a2.shape[1]):\n",
    "            a2[i,j,7] = vgr[3,j,i]    # v-wind at 900 mb\n",
    "            a2[i,j,8] = vgr[17,j,i]   # v-wind at 300 mb\n",
    "    hgt = f.variables['hgtprs']\n",
    "    for i in range(a2.shape[0]):\n",
    "        for j in range(a2.shape[1]):\n",
    "            a2[i,j,9] = hgt[3,j,i]    # geopotential at 850 mb\n",
    "    wgr = f.variables['vvelprs']\n",
    "    for i in range(a2.shape[0]):\n",
    "        for j in range(a2.shape[1]):\n",
    "            a2[i,j,10] = wgr[3,j,i]   # w-wind at 900 mb\n",
    "            a2[i,j,11] = wgr[17,j,i]  # w-wind at 300 mb\n",
    "    new_array = cv2.resize(a2, (IMG_SIZE_X, IMG_SIZE_Y))\n",
    "    #\n",
    "    # normalize the data\n",
    "    #\n",
    "    for var in range(number_channels):\n",
    "        maxvalue = new_array[:,:,var].flat[np.abs(new_array[:,:,var]).argmax()]\n",
    "        #print('Normalization factor for channel',var,', is: ',abs(maxvalue))\n",
    "        new_array[:,:,var] = new_array[:,:,var]/abs(maxvalue)\n",
    "    out_array = np.expand_dims(new_array,axis=0)    \n",
    "    #out_array = np.reshape(new_array, (-1, IMG_SIZE_Y, IMG_SIZE_X, number_channels))\n",
    "    #print('reshape new_array returns: ',out_array.shape)\n",
    "    #input('Enter to continue...')\n",
    "    return out_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4354361",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# build an F1-score function for later use\n",
    "#\n",
    "def F1_score(y_true,y_prediction,true_class,true_threshold):\n",
    "    T = len(y_true)\n",
    "    if len(y_prediction) != T:\n",
    "        print(\"Prediction and true label arrays have different size. Stop\")\n",
    "        return\n",
    "    P = 0\n",
    "    TP = 0 \n",
    "    FN = 0\n",
    "    TN = 0\n",
    "    FP = 0\n",
    "    for i in range(T):\n",
    "        if y_true[i] == true_class:\n",
    "            P = P + 1       \n",
    "            if y_prediction[i] >= true_threshold:\n",
    "                TP += 1 \n",
    "            else:\n",
    "                FN += 1\n",
    "        else:\n",
    "            if y_prediction[i] >= true_threshold:\n",
    "                FP += 1 \n",
    "            else:\n",
    "                TN += 1            \n",
    "    N = T - P    \n",
    "    F1 = 2.*TP/(2.*TP + FP + FN)\n",
    "    Recall = TP/float(TP+FN)\n",
    "    if TP == 0 and FP == 0: \n",
    "        Precision = 0.\n",
    "    else:    \n",
    "        Precision = TP/float(TP+FP)\n",
    "    return F1, Recall, Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3c2815a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                                                                                                 | 0/158 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: /N/slate/ckieu/tmp/output/ncep_extracted_41x161_12h/test/pos/fnl_20210806_00_00.nc\n",
      "Input image dimension is:  (1, 64, 128, 12)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-07 14:08:09.078149: E tensorflow/stream_executor/cuda/cuda_dnn.cc:389] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR\n",
      "2023-08-07 14:08:09.078659: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at conv_ops.cc:1120 : UNIMPLEMENTED: DNN library is not found.\n",
      "  1%|▉                                                                                                                                                      | 1/158 [00:36<1:35:14, 36.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: /N/slate/ckieu/tmp/output/ncep_extracted_41x161_12h/test/pos/fnl_20200915_06_00.nc\n",
      "Input image dimension is:  (1, 64, 128, 12)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_37773/68616811.py:16: UserWarning: WARNING: _FillValue not used since it\n",
      "cannot be safely cast to variable data type\n",
      "  a2[i,j,0] = abv[1,j,i]    # abs vort at 950 mb\n",
      "  1%|▉                                                                                                                                                      | 1/158 [00:51<2:15:25, 51.75s/it]\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# loop thru all best-saved CNN trained models and make a prediction. Note that prediction is applied one by one instead \n",
    "# of a batch input. \n",
    "#\n",
    "DATADIR = \"/N/slate/ckieu/tmp/output/ncep_extracted_41x161_12h/test\"\n",
    "bestmodels = [\"tcg_segment_model.keras\"]\n",
    "CATEGORIES = [\"pos\",\"neg\"]\n",
    "F1_performance = []\n",
    "for bestmodel in bestmodels:\n",
    "    model = keras.models.load_model(bestmodel)\n",
    "    prediction_total = 0\n",
    "    prediction_yes = 0\n",
    "    prediction_history = []\n",
    "    truth_history = []\n",
    "    for category in CATEGORIES:\n",
    "        path = os.path.join(DATADIR,category)\n",
    "        for img in tqdm(os.listdir(path)):    \n",
    "            try:\n",
    "                img_dir = DATADIR + '/' + category + '/' + img\n",
    "                print('Processing image:', img_dir)\n",
    "                print('Input image dimension is: ',prepare(img_dir).shape)\n",
    "                batch_predictions = model.predict([prepare(img_dir)])\n",
    "                print('OK prediction batch')\n",
    "                prediction = batch_predictions[0]\n",
    "                \n",
    "                #print(\"TC formation prediction is\",prediction,round(prediction[0][0]),CATEGORIES[round(prediction[0][0])])\n",
    "                #prediction_history.append(prediction[0][0])\n",
    "                #if round(prediction[0][0]) == 1:\n",
    "                #    prediction_yes += 1\n",
    "                #if category == \"pos\":\n",
    "                #    truth_history.append(1)\n",
    "                #else:\n",
    "                #    truth_history.append(0)\n",
    "                prediction_total += 1    \n",
    "                if prediction_total > 1:\n",
    "                    print(\"prediction_total = \",prediction_total)\n",
    "                    break\n",
    "            except Exception as e:\n",
    "                pass   \n",
    "            #input(\"Press Enter to continue...\")    \n",
    "    #\n",
    "    # Compute F1 score for each best model now\n",
    "    #\n",
    "    #print(prediction_history)\n",
    "    #F1_performance.append([bestmodel,F1_score(truth_history,prediction_history,1,0.5)]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6cca054",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.contourf(prediction[:,:,0])\n",
    "plt.colorbar()\n",
    "plt.figure()\n",
    "plt.contourf(prediction[:,:,1])\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c80549e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9999962, 1], [0.6882587, 1], [0.9955371, 1], [0.85128695, 1], [0.97033226, 1], [0.09757158, 0], [0.99786943, 1], [1.0, 1], [0.99999934, 1], [0.9987997, 1], [0.96775466, 1], [0.55922717, 1], [0.9999991, 1], [0.9999858, 1], [1.0, 1], [0.99997646, 1], [0.9990219, 1], [0.99999243, 1], [0.99574035, 1], [0.99985635, 1], [0.99976224, 1], [0.008809361, 0], [0.7542709, 1], [0.98565555, 1], [0.9934654, 1], [0.00093312794, 0], [1.0, 1], [0.9999476, 1], [0.9929507, 1], [0.0015317168, 0], [0.9999999, 1], [0.6828572, 1], [0.9999997, 1], [0.9999999, 1], [0.993845, 1], [0.9964261, 1], [0.9963727, 1], [0.0017297732, 0], [0.9999232, 1], [0.99999267, 1], [0.99957865, 1], [0.98262095, 1], [0.99999493, 1], [0.9999934, 1], [0.99553144, 1], [0.991998, 1], [0.9999994, 1], [0.9999998, 1], [0.9999995, 1], [0.999895, 1], [0.7519042, 1]]\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Print out the F1 performance of all models\n",
    "#\n",
    "print(\"F1, Recall, Precision for all models are:\")\n",
    "for i in range(len(bestmodels)):\n",
    "    print(\"Model:\", F1_performance[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
