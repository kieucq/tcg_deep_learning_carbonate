{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "177fa5fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-20 13:57:40.783460: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# NOTE: This machine learning program is for predicting TC formation, using\n",
    "#       input dataset in the NETCDF format. The program treats different\n",
    "#       2D input fields as different channels of an image. This specific\n",
    "#       program requires a set of 12 2D-variables (12-channel image) and\n",
    "#       consists of three stages\n",
    "#       - Stage 1: reading NETCDF input and generating (X,y) data with a\n",
    "#                  given image sizes, which are then saved by pickle;\n",
    "#       - Stage 2: import the saved pickle (X,y) pair and build a CNN model\n",
    "#                  with a given training/validation ratio, and then save\n",
    "#                  the train model under tcg_CNN.model.\n",
    "#       - Stage 3: import the trained model from Stage 2, and make a list\n",
    "#                  of prediction from normalized test data.\n",
    "#\n",
    "# INPUT: This Stage 2 script requires two specific input datasets that are\n",
    "#        generated from Step 1, including\n",
    "#        1. tcg_X.pickle: data contains all images of yes/no TCG events, each\n",
    "#           of these images must have 12 channels\n",
    "#        2. tcg_y.pickle: data contains all labels of each image (i.e., yes\n",
    "#           or no) of TCG corresponding to each data in X.\n",
    "#\n",
    "#        Remarks: Note that each channel must be normalized separealy. Also\n",
    "#        the script requires a large memory allocation. So users need to have\n",
    "#        GPU version to run this.\n",
    "#\n",
    "# OUTPUT: A CNN model built from Keras saved under tcg_CNN.model\n",
    "#\n",
    "# HIST: - 27, Oct 22: Created by CK\n",
    "#       - 01, Nov 22: Modified to include more channels\n",
    "#       - 17, Nov 23: cusomize it for jupiter notebook\n",
    "#       - 21, Feb 23: use functional model instead of sequential model  \n",
    "#       - 05, Jun 23: Re-check for consistency with Stage 1 script and added more hyperparamter loops\n",
    "#       - 20, Jun 23: Updated for augmentation/dropout layers\n",
    "#\n",
    "# AUTH: Chanh Kieu (Indiana University, Bloomington. Email: ckieu@iu.edu)\n",
    "#\n",
    "#==========================================================================\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84e03120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape of the X features data:  (704, 30, 30, 12)\n",
      "Input shape of the y label data:  (704,)\n",
      "Number of input channel extracted from X is:  12\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# read in data output from Part 1\n",
    "#\n",
    "pickle_in = open(\"tcg_CNNaugment_X.pickle\",\"rb\")\n",
    "X = pickle.load(pickle_in)\n",
    "pickle_in = open(\"tcg_CNNaugment_y.pickle\",\"rb\")\n",
    "y = pickle.load(pickle_in)\n",
    "y = np.array(y)\n",
    "number_channels=X.shape[3]\n",
    "print('Input shape of the X features data: ',X.shape)\n",
    "print('Input shape of the y label data: ',y.shape)\n",
    "print('Number of input channel extracted from X is: ',number_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd4b03c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish normalization...\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# normalize the data before training the model\n",
    "#\n",
    "nsample = X.shape[0]\n",
    "for i in range(nsample):\n",
    "    for var in range(number_channels):    \n",
    "        maxvalue = X[i,:,:,var].flat[np.abs(X[i,:,:,var]).argmax()]\n",
    "        #print('Normalization factor for sample and channel',i,var,', is: ',abs(maxvalue))\n",
    "        X[i,:,:,var] = X[i,:,:,var]/abs(maxvalue)\n",
    "        maxnew = X[i,:,:,var].flat[np.abs(X[i,:,:,var]).argmax()]\n",
    "        #print('-->After normalization of sample and channel',i,var,', is: ',abs(maxnew))\n",
    "        #input('Enter to continue...')\n",
    "print(\"Finish normalization...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "716ab205",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-20 13:58:50.023596: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-20 13:58:53.615387: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30987 MB memory:  -> device: 0, name: Tesla V100-PCIE-32GB, pci bus id: 0000:b1:00.0, compute capability: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> Running configuration:  3-conv-32-layer-0-dense.model_00h\n",
      "Model: \"my_functional_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 30, 30, 12)]      0         \n",
      "                                                                 \n",
      " sequential (Sequential)     (None, 30, 30, 12)        0         \n",
      "                                                                 \n",
      " my_conv2d_1 (Conv2D)        (None, 28, 28, 32)        3488      \n",
      "                                                                 \n",
      " my_pooling_1 (MaxPooling2D)  (None, 14, 14, 32)       0         \n",
      "                                                                 \n",
      " my_conv2d_2 (Conv2D)        (None, 12, 12, 64)        18496     \n",
      "                                                                 \n",
      " my_pooling_2 (MaxPooling2D)  (None, 6, 6, 64)         0         \n",
      "                                                                 \n",
      " my_conv2d_3 (Conv2D)        (None, 4, 4, 128)         73856     \n",
      "                                                                 \n",
      " my_pooling_3 (MaxPooling2D)  (None, 2, 2, 128)        0         \n",
      "                                                                 \n",
      " my_flatten (Flatten)        (None, 512)               0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " my_dense (Dense)            (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 96,353\n",
      "Trainable params: 96,353\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-20 13:59:02.184070: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8401\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - ETA: 0s - loss: 0.6495 - accuracy: 0.6461"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 3-conv-32-layer-0-dense.model_00h/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 3-conv-32-layer-0-dense.model_00h/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 18s 551ms/step - loss: 0.6495 - accuracy: 0.6461 - val_loss: 0.5413 - val_accuracy: 0.8169\n",
      "Epoch 2/30\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.4414 - accuracy: 0.8847"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 3-conv-32-layer-0-dense.model_00h/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 3-conv-32-layer-0-dense.model_00h/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 481ms/step - loss: 0.4414 - accuracy: 0.8847 - val_loss: 0.2828 - val_accuracy: 0.9437\n",
      "Epoch 3/30\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.2584 - accuracy: 0.9084"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 3-conv-32-layer-0-dense.model_00h/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 3-conv-32-layer-0-dense.model_00h/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 432ms/step - loss: 0.2584 - accuracy: 0.9084 - val_loss: 0.1917 - val_accuracy: 0.9437\n",
      "Epoch 4/30\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.2021 - accuracy: 0.9131"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 3-conv-32-layer-0-dense.model_00h/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 3-conv-32-layer-0-dense.model_00h/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 431ms/step - loss: 0.2021 - accuracy: 0.9131 - val_loss: 0.1603 - val_accuracy: 0.9437\n",
      "Epoch 5/30\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 0.1889 - accuracy: 0.9179 - val_loss: 0.1653 - val_accuracy: 0.9296\n",
      "Epoch 6/30\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 0.1499 - accuracy: 0.9352 - val_loss: 0.2331 - val_accuracy: 0.9155\n",
      "Epoch 7/30\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.1745 - accuracy: 0.9321"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 3-conv-32-layer-0-dense.model_00h/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 3-conv-32-layer-0-dense.model_00h/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 507ms/step - loss: 0.1745 - accuracy: 0.9321 - val_loss: 0.1428 - val_accuracy: 0.9437\n",
      "Epoch 8/30\n",
      "5/5 [==============================] - 0s 72ms/step - loss: 0.1568 - accuracy: 0.9415 - val_loss: 0.2531 - val_accuracy: 0.9014\n",
      "Epoch 9/30\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.1268 - accuracy: 0.9510"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 3-conv-32-layer-0-dense.model_00h/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 3-conv-32-layer-0-dense.model_00h/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 434ms/step - loss: 0.1268 - accuracy: 0.9510 - val_loss: 0.1267 - val_accuracy: 0.9577\n",
      "Epoch 10/30\n",
      "5/5 [==============================] - 0s 76ms/step - loss: 0.1393 - accuracy: 0.9510 - val_loss: 0.1751 - val_accuracy: 0.9155\n",
      "Epoch 11/30\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.1129 - accuracy: 0.9494"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 3-conv-32-layer-0-dense.model_00h/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 3-conv-32-layer-0-dense.model_00h/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 504ms/step - loss: 0.1129 - accuracy: 0.9494 - val_loss: 0.1086 - val_accuracy: 0.9718\n",
      "Epoch 12/30\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 0.1047 - accuracy: 0.9589 - val_loss: 0.1632 - val_accuracy: 0.9296\n",
      "Epoch 13/30\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 0.0975 - accuracy: 0.9716 - val_loss: 0.1097 - val_accuracy: 0.9437\n",
      "Epoch 14/30\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 0.0956 - accuracy: 0.9621 - val_loss: 0.1226 - val_accuracy: 0.9437\n",
      "Epoch 15/30\n",
      "5/5 [==============================] - 0s 76ms/step - loss: 0.0950 - accuracy: 0.9573 - val_loss: 0.1415 - val_accuracy: 0.9296\n",
      "Epoch 16/30\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 0.0829 - accuracy: 0.9700 - val_loss: 0.1149 - val_accuracy: 0.9437\n",
      "Epoch 17/30\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 0.0660 - accuracy: 0.9747 - val_loss: 0.1356 - val_accuracy: 0.9437\n",
      "Epoch 18/30\n",
      "5/5 [==============================] - 0s 72ms/step - loss: 0.0591 - accuracy: 0.9763 - val_loss: 0.1190 - val_accuracy: 0.9577\n",
      "Epoch 19/30\n",
      "5/5 [==============================] - 0s 72ms/step - loss: 0.0698 - accuracy: 0.9763 - val_loss: 0.1679 - val_accuracy: 0.9437\n",
      "Epoch 20/30\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 0.0578 - accuracy: 0.9779 - val_loss: 0.1324 - val_accuracy: 0.9577\n",
      "Epoch 21/30\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 0.0678 - accuracy: 0.9810 - val_loss: 0.1198 - val_accuracy: 0.9577\n",
      "Epoch 22/30\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 0.0680 - accuracy: 0.9700 - val_loss: 0.2524 - val_accuracy: 0.9437\n",
      "Epoch 23/30\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 0.0797 - accuracy: 0.9652 - val_loss: 0.1143 - val_accuracy: 0.9437\n",
      "Epoch 24/30\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 0.0698 - accuracy: 0.9700 - val_loss: 0.2197 - val_accuracy: 0.9437\n",
      "Epoch 25/30\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 0.0625 - accuracy: 0.9747 - val_loss: 0.1244 - val_accuracy: 0.9577\n",
      "Epoch 26/30\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 0.0512 - accuracy: 0.9842 - val_loss: 0.1817 - val_accuracy: 0.9437\n",
      "Epoch 27/30\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 0.0518 - accuracy: 0.9826 - val_loss: 0.1304 - val_accuracy: 0.9577\n",
      "Epoch 28/30\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 0.0441 - accuracy: 0.9921 - val_loss: 0.1409 - val_accuracy: 0.9437\n",
      "Epoch 29/30\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 0.0403 - accuracy: 0.9858 - val_loss: 0.1398 - val_accuracy: 0.9577\n",
      "Epoch 30/30\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 0.0312 - accuracy: 0.9937 - val_loss: 0.1457 - val_accuracy: 0.9577\n",
      "--> Running configuration:  5-conv-32-layer-0-dense.model_00h\n",
      "Model: \"my_functional_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 30, 30, 12)]      0         \n",
      "                                                                 \n",
      " sequential (Sequential)     (None, 30, 30, 12)        0         \n",
      "                                                                 \n",
      " my_conv2d_1 (Conv2D)        (None, 26, 26, 32)        9632      \n",
      "                                                                 \n",
      " my_pooling_1 (MaxPooling2D)  (None, 13, 13, 32)       0         \n",
      "                                                                 \n",
      " my_conv2d_2 (Conv2D)        (None, 9, 9, 64)          51264     \n",
      "                                                                 \n",
      " my_pooling_2 (MaxPooling2D)  (None, 4, 4, 64)         0         \n",
      "                                                                 \n",
      " my_flatten (Flatten)        (None, 1024)              0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 1024)              0         \n",
      "                                                                 \n",
      " my_dense (Dense)            (None, 1)                 1025      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 61,921\n",
      "Trainable params: 61,921\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.5802 - accuracy: 0.7567"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 5-conv-32-layer-0-dense.model_00h/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 5-conv-32-layer-0-dense.model_00h/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 3s 451ms/step - loss: 0.5802 - accuracy: 0.7567 - val_loss: 0.3790 - val_accuracy: 0.9296\n",
      "Epoch 2/30\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.3132 - accuracy: 0.8942"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 5-conv-32-layer-0-dense.model_00h/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 5-conv-32-layer-0-dense.model_00h/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 489ms/step - loss: 0.3132 - accuracy: 0.8942 - val_loss: 0.2097 - val_accuracy: 0.9014\n",
      "Epoch 3/30\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.2259 - accuracy: 0.9084"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 5-conv-32-layer-0-dense.model_00h/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 5-conv-32-layer-0-dense.model_00h/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 424ms/step - loss: 0.2259 - accuracy: 0.9084 - val_loss: 0.1944 - val_accuracy: 0.9155\n",
      "Epoch 4/30\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.2081 - accuracy: 0.9052"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 5-conv-32-layer-0-dense.model_00h/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 5-conv-32-layer-0-dense.model_00h/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 403ms/step - loss: 0.2081 - accuracy: 0.9052 - val_loss: 0.1852 - val_accuracy: 0.9296\n",
      "Epoch 5/30\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 0.1784 - accuracy: 0.9226 - val_loss: 0.3074 - val_accuracy: 0.8873\n",
      "Epoch 6/30\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.1551 - accuracy: 0.9305"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 5-conv-32-layer-0-dense.model_00h/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 5-conv-32-layer-0-dense.model_00h/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 500ms/step - loss: 0.1551 - accuracy: 0.9305 - val_loss: 0.1526 - val_accuracy: 0.9296\n",
      "Epoch 7/30\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 0.1442 - accuracy: 0.9400 - val_loss: 0.1923 - val_accuracy: 0.9296\n",
      "Epoch 8/30\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.1378 - accuracy: 0.9431"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 5-conv-32-layer-0-dense.model_00h/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 5-conv-32-layer-0-dense.model_00h/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 417ms/step - loss: 0.1378 - accuracy: 0.9431 - val_loss: 0.1415 - val_accuracy: 0.9296\n",
      "Epoch 9/30\n",
      "5/5 [==============================] - 0s 72ms/step - loss: 0.1241 - accuracy: 0.9558 - val_loss: 0.1593 - val_accuracy: 0.9437\n",
      "Epoch 10/30\n",
      "5/5 [==============================] - 0s 72ms/step - loss: 0.1134 - accuracy: 0.9494 - val_loss: 0.1431 - val_accuracy: 0.9296\n",
      "Epoch 11/30\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 0.1025 - accuracy: 0.9573 - val_loss: 0.1437 - val_accuracy: 0.9437\n",
      "Epoch 12/30\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 0.0963 - accuracy: 0.9605 - val_loss: 0.1470 - val_accuracy: 0.9437\n",
      "Epoch 13/30\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.1034 - accuracy: 0.9605"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 5-conv-32-layer-0-dense.model_00h/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 5-conv-32-layer-0-dense.model_00h/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 408ms/step - loss: 0.1034 - accuracy: 0.9605 - val_loss: 0.1241 - val_accuracy: 0.9437\n",
      "Epoch 14/30\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 0.0773 - accuracy: 0.9684 - val_loss: 0.1395 - val_accuracy: 0.9437\n",
      "Epoch 15/30\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 0.0800 - accuracy: 0.9684 - val_loss: 0.1457 - val_accuracy: 0.9437\n",
      "Epoch 16/30\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0711 - accuracy: 0.9684"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 5-conv-32-layer-0-dense.model_00h/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 5-conv-32-layer-0-dense.model_00h/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 551ms/step - loss: 0.0711 - accuracy: 0.9684 - val_loss: 0.1165 - val_accuracy: 0.9437\n",
      "Epoch 17/30\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 0.0824 - accuracy: 0.9716 - val_loss: 0.1320 - val_accuracy: 0.9577\n",
      "Epoch 18/30\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 0.0762 - accuracy: 0.9668 - val_loss: 0.1380 - val_accuracy: 0.9577\n",
      "Epoch 19/30\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0604 - accuracy: 0.9763"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 5-conv-32-layer-0-dense.model_00h/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 5-conv-32-layer-0-dense.model_00h/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 408ms/step - loss: 0.0604 - accuracy: 0.9763 - val_loss: 0.1062 - val_accuracy: 0.9437\n",
      "Epoch 20/30\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 0.0699 - accuracy: 0.9684 - val_loss: 0.1580 - val_accuracy: 0.9577\n",
      "Epoch 21/30\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 0.0693 - accuracy: 0.9763 - val_loss: 0.1069 - val_accuracy: 0.9296\n",
      "Epoch 22/30\n",
      "5/5 [==============================] - 0s 71ms/step - loss: 0.0582 - accuracy: 0.9795 - val_loss: 0.1355 - val_accuracy: 0.9577\n",
      "Epoch 23/30\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 0.0488 - accuracy: 0.9826 - val_loss: 0.1068 - val_accuracy: 0.9577\n",
      "Epoch 24/30\n",
      "5/5 [==============================] - 0s 72ms/step - loss: 0.0468 - accuracy: 0.9826 - val_loss: 0.1315 - val_accuracy: 0.9577\n",
      "Epoch 25/30\n",
      "5/5 [==============================] - 0s 72ms/step - loss: 0.0502 - accuracy: 0.9810 - val_loss: 0.1159 - val_accuracy: 0.9577\n",
      "Epoch 26/30\n",
      "5/5 [==============================] - 0s 72ms/step - loss: 0.0456 - accuracy: 0.9842 - val_loss: 0.1296 - val_accuracy: 0.9577\n",
      "Epoch 27/30\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 0.0483 - accuracy: 0.9842 - val_loss: 0.1370 - val_accuracy: 0.9577\n",
      "Epoch 28/30\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0347 - accuracy: 0.9921"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 5-conv-32-layer-0-dense.model_00h/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 5-conv-32-layer-0-dense.model_00h/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 402ms/step - loss: 0.0347 - accuracy: 0.9921 - val_loss: 0.1032 - val_accuracy: 0.9577\n",
      "Epoch 29/30\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 0.0433 - accuracy: 0.9842 - val_loss: 0.1200 - val_accuracy: 0.9577\n",
      "Epoch 30/30\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0472 - accuracy: 0.9842"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 5-conv-32-layer-0-dense.model_00h/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 5-conv-32-layer-0-dense.model_00h/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 497ms/step - loss: 0.0472 - accuracy: 0.9842 - val_loss: 0.0937 - val_accuracy: 0.9577\n",
      "--> Running configuration:  3-conv-32-layer-1-dense.model_00h\n",
      "Model: \"my_functional_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 30, 30, 12)]      0         \n",
      "                                                                 \n",
      " sequential (Sequential)     (None, 30, 30, 12)        0         \n",
      "                                                                 \n",
      " my_conv2d_1 (Conv2D)        (None, 28, 28, 32)        3488      \n",
      "                                                                 \n",
      " my_pooling_1 (MaxPooling2D)  (None, 14, 14, 32)       0         \n",
      "                                                                 \n",
      " my_conv2d_2 (Conv2D)        (None, 12, 12, 64)        18496     \n",
      "                                                                 \n",
      " my_pooling_2 (MaxPooling2D)  (None, 6, 6, 64)         0         \n",
      "                                                                 \n",
      " my_conv2d_3 (Conv2D)        (None, 4, 4, 128)         73856     \n",
      "                                                                 \n",
      " my_pooling_3 (MaxPooling2D)  (None, 2, 2, 128)        0         \n",
      "                                                                 \n",
      " my_flatten (Flatten)        (None, 512)               0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                16416     \n",
      "                                                                 \n",
      " my_dense (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 112,289\n",
      "Trainable params: 112,289\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.6591 - accuracy: 0.5671"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 3-conv-32-layer-1-dense.model_00h/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 3-conv-32-layer-1-dense.model_00h/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 3s 476ms/step - loss: 0.6591 - accuracy: 0.5671 - val_loss: 0.5608 - val_accuracy: 0.8873\n",
      "Epoch 2/30\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.5180 - accuracy: 0.8120"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 3-conv-32-layer-1-dense.model_00h/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 3-conv-32-layer-1-dense.model_00h/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 537ms/step - loss: 0.5180 - accuracy: 0.8120 - val_loss: 0.4160 - val_accuracy: 0.8592\n",
      "Epoch 3/30\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.3870 - accuracy: 0.8452"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 3-conv-32-layer-1-dense.model_00h/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 3-conv-32-layer-1-dense.model_00h/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 453ms/step - loss: 0.3870 - accuracy: 0.8452 - val_loss: 0.2366 - val_accuracy: 0.9155\n",
      "Epoch 4/30\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 0.3022 - accuracy: 0.8736 - val_loss: 0.2954 - val_accuracy: 0.8732\n",
      "Epoch 5/30\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.2438 - accuracy: 0.9036"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 3-conv-32-layer-1-dense.model_00h/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 3-conv-32-layer-1-dense.model_00h/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 453ms/step - loss: 0.2438 - accuracy: 0.9036 - val_loss: 0.1944 - val_accuracy: 0.9014\n",
      "Epoch 6/30\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 0.2271 - accuracy: 0.9100 - val_loss: 0.2140 - val_accuracy: 0.9155\n",
      "Epoch 7/30\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.1848 - accuracy: 0.9226"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 3-conv-32-layer-1-dense.model_00h/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 3-conv-32-layer-1-dense.model_00h/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 534ms/step - loss: 0.1848 - accuracy: 0.9226 - val_loss: 0.1809 - val_accuracy: 0.9296\n",
      "Epoch 8/30\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.1686 - accuracy: 0.9352"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 3-conv-32-layer-1-dense.model_00h/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 3-conv-32-layer-1-dense.model_00h/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 453ms/step - loss: 0.1686 - accuracy: 0.9352 - val_loss: 0.1661 - val_accuracy: 0.9296\n",
      "Epoch 9/30\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.1457 - accuracy: 0.9479"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 3-conv-32-layer-1-dense.model_00h/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 3-conv-32-layer-1-dense.model_00h/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 453ms/step - loss: 0.1457 - accuracy: 0.9479 - val_loss: 0.1545 - val_accuracy: 0.9155\n",
      "Epoch 10/30\n",
      "5/5 [==============================] - 0s 76ms/step - loss: 0.1463 - accuracy: 0.9368 - val_loss: 0.1726 - val_accuracy: 0.9296\n",
      "Epoch 11/30\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.1180 - accuracy: 0.9510"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 3-conv-32-layer-1-dense.model_00h/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 3-conv-32-layer-1-dense.model_00h/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 539ms/step - loss: 0.1180 - accuracy: 0.9510 - val_loss: 0.1179 - val_accuracy: 0.9296\n",
      "Epoch 12/30\n",
      "5/5 [==============================] - 0s 76ms/step - loss: 0.1117 - accuracy: 0.9526 - val_loss: 0.1295 - val_accuracy: 0.9437\n",
      "Epoch 13/30\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 0.1033 - accuracy: 0.9637 - val_loss: 0.1201 - val_accuracy: 0.9437\n",
      "Epoch 14/30\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0847 - accuracy: 0.9652"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 3-conv-32-layer-1-dense.model_00h/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 3-conv-32-layer-1-dense.model_00h/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 451ms/step - loss: 0.0847 - accuracy: 0.9652 - val_loss: 0.0957 - val_accuracy: 0.9437\n",
      "Epoch 15/30\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 0.0885 - accuracy: 0.9668 - val_loss: 0.1096 - val_accuracy: 0.9437\n",
      "Epoch 16/30\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 0.0713 - accuracy: 0.9700 - val_loss: 0.1145 - val_accuracy: 0.9437\n",
      "Epoch 17/30\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 0.0691 - accuracy: 0.9731 - val_loss: 0.1686 - val_accuracy: 0.9437\n",
      "Epoch 18/30\n",
      "5/5 [==============================] - 0s 77ms/step - loss: 0.0710 - accuracy: 0.9684 - val_loss: 0.1232 - val_accuracy: 0.9577\n",
      "Epoch 19/30\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 0.0570 - accuracy: 0.9810 - val_loss: 0.1171 - val_accuracy: 0.9577\n",
      "Epoch 20/30\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 0.0552 - accuracy: 0.9763 - val_loss: 0.0981 - val_accuracy: 0.9577\n",
      "Epoch 21/30\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 0.0563 - accuracy: 0.9779 - val_loss: 0.1534 - val_accuracy: 0.9437\n",
      "Epoch 22/30\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 0.0425 - accuracy: 0.9842 - val_loss: 0.1779 - val_accuracy: 0.9437\n",
      "Epoch 23/30\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 0.0411 - accuracy: 0.9858 - val_loss: 0.1639 - val_accuracy: 0.9437\n",
      "Epoch 24/30\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 0.0492 - accuracy: 0.9826 - val_loss: 0.1026 - val_accuracy: 0.9437\n",
      "Epoch 25/30\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 0.0383 - accuracy: 0.9858 - val_loss: 0.1061 - val_accuracy: 0.9577\n",
      "Epoch 26/30\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 0.0457 - accuracy: 0.9874 - val_loss: 0.0994 - val_accuracy: 0.9437\n",
      "Epoch 27/30\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 0.0385 - accuracy: 0.9874 - val_loss: 0.1193 - val_accuracy: 0.9437\n",
      "Epoch 28/30\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 0.0363 - accuracy: 0.9905 - val_loss: 0.1296 - val_accuracy: 0.9577\n",
      "Epoch 29/30\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 0.0262 - accuracy: 0.9889 - val_loss: 0.1604 - val_accuracy: 0.9577\n",
      "Epoch 30/30\n",
      "5/5 [==============================] - 0s 76ms/step - loss: 0.0295 - accuracy: 0.9889 - val_loss: 0.1138 - val_accuracy: 0.9437\n",
      "--> Running configuration:  5-conv-32-layer-1-dense.model_00h\n",
      "Model: \"my_functional_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 30, 30, 12)]      0         \n",
      "                                                                 \n",
      " sequential (Sequential)     (None, 30, 30, 12)        0         \n",
      "                                                                 \n",
      " my_conv2d_1 (Conv2D)        (None, 26, 26, 32)        9632      \n",
      "                                                                 \n",
      " my_pooling_1 (MaxPooling2D)  (None, 13, 13, 32)       0         \n",
      "                                                                 \n",
      " my_conv2d_2 (Conv2D)        (None, 9, 9, 64)          51264     \n",
      "                                                                 \n",
      " my_pooling_2 (MaxPooling2D)  (None, 4, 4, 64)         0         \n",
      "                                                                 \n",
      " my_flatten (Flatten)        (None, 1024)              0         \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                32800     \n",
      "                                                                 \n",
      " my_dense (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 93,729\n",
      "Trainable params: 93,729\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.6184 - accuracy: 0.6746"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 5-conv-32-layer-1-dense.model_00h/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 5-conv-32-layer-1-dense.model_00h/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 3s 533ms/step - loss: 0.6184 - accuracy: 0.6746 - val_loss: 0.4309 - val_accuracy: 0.8592\n",
      "Epoch 2/30\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.3207 - accuracy: 0.8910"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 5-conv-32-layer-1-dense.model_00h/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 5-conv-32-layer-1-dense.model_00h/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 441ms/step - loss: 0.3207 - accuracy: 0.8910 - val_loss: 0.2215 - val_accuracy: 0.9155\n",
      "Epoch 3/30\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.2231 - accuracy: 0.9115"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 5-conv-32-layer-1-dense.model_00h/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 5-conv-32-layer-1-dense.model_00h/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 502ms/step - loss: 0.2231 - accuracy: 0.9115 - val_loss: 0.2070 - val_accuracy: 0.9296\n",
      "Epoch 4/30\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.2022 - accuracy: 0.9179"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 5-conv-32-layer-1-dense.model_00h/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 5-conv-32-layer-1-dense.model_00h/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 439ms/step - loss: 0.2022 - accuracy: 0.9179 - val_loss: 0.2014 - val_accuracy: 0.9014\n",
      "Epoch 5/30\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.1734 - accuracy: 0.9336"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 5-conv-32-layer-1-dense.model_00h/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 5-conv-32-layer-1-dense.model_00h/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 425ms/step - loss: 0.1734 - accuracy: 0.9336 - val_loss: 0.1531 - val_accuracy: 0.9296\n",
      "Epoch 6/30\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.1453 - accuracy: 0.9336"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 5-conv-32-layer-1-dense.model_00h/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 5-conv-32-layer-1-dense.model_00h/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 512ms/step - loss: 0.1453 - accuracy: 0.9336 - val_loss: 0.1440 - val_accuracy: 0.9296\n",
      "Epoch 7/30\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 0.1300 - accuracy: 0.9558 - val_loss: 0.1533 - val_accuracy: 0.9296\n",
      "Epoch 8/30\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.1228 - accuracy: 0.9510"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 5-conv-32-layer-1-dense.model_00h/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 5-conv-32-layer-1-dense.model_00h/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 434ms/step - loss: 0.1228 - accuracy: 0.9510 - val_loss: 0.1360 - val_accuracy: 0.9437\n",
      "Epoch 9/30\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.1093 - accuracy: 0.9479"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 5-conv-32-layer-1-dense.model_00h/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 5-conv-32-layer-1-dense.model_00h/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 415ms/step - loss: 0.1093 - accuracy: 0.9479 - val_loss: 0.1199 - val_accuracy: 0.9155\n",
      "Epoch 10/30\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0922 - accuracy: 0.9652"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 5-conv-32-layer-1-dense.model_00h/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 5-conv-32-layer-1-dense.model_00h/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 515ms/step - loss: 0.0922 - accuracy: 0.9652 - val_loss: 0.0989 - val_accuracy: 0.9437\n",
      "Epoch 11/30\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.1072 - accuracy: 0.9605"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 5-conv-32-layer-1-dense.model_00h/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 5-conv-32-layer-1-dense.model_00h/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 422ms/step - loss: 0.1072 - accuracy: 0.9605 - val_loss: 0.0879 - val_accuracy: 0.9718\n",
      "Epoch 12/30\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 0.0821 - accuracy: 0.9684 - val_loss: 0.0920 - val_accuracy: 0.9577\n",
      "Epoch 13/30\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 0.0819 - accuracy: 0.9684 - val_loss: 0.1239 - val_accuracy: 0.9437\n",
      "Epoch 14/30\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 0.0790 - accuracy: 0.9684 - val_loss: 0.1571 - val_accuracy: 0.9437\n",
      "Epoch 15/30\n",
      "5/5 [==============================] - 0s 72ms/step - loss: 0.1172 - accuracy: 0.9542 - val_loss: 0.0985 - val_accuracy: 0.9577\n",
      "Epoch 16/30\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 0.0955 - accuracy: 0.9605 - val_loss: 0.1291 - val_accuracy: 0.9577\n",
      "Epoch 17/30\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 0.0907 - accuracy: 0.9684 - val_loss: 0.0997 - val_accuracy: 0.9577\n",
      "Epoch 18/30\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 0.0611 - accuracy: 0.9731 - val_loss: 0.1050 - val_accuracy: 0.9577\n",
      "Epoch 19/30\n",
      "5/5 [==============================] - 0s 72ms/step - loss: 0.0612 - accuracy: 0.9810 - val_loss: 0.1227 - val_accuracy: 0.9577\n",
      "Epoch 20/30\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0644 - accuracy: 0.9716"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 5-conv-32-layer-1-dense.model_00h/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 5-conv-32-layer-1-dense.model_00h/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 429ms/step - loss: 0.0644 - accuracy: 0.9716 - val_loss: 0.0853 - val_accuracy: 0.9577\n",
      "Epoch 21/30\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 0.0571 - accuracy: 0.9795 - val_loss: 0.1174 - val_accuracy: 0.9577\n",
      "Epoch 22/30\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0515 - accuracy: 0.9842"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 5-conv-32-layer-1-dense.model_00h/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 5-conv-32-layer-1-dense.model_00h/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 518ms/step - loss: 0.0515 - accuracy: 0.9842 - val_loss: 0.0792 - val_accuracy: 0.9718\n",
      "Epoch 23/30\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 0.0681 - accuracy: 0.9731 - val_loss: 0.1494 - val_accuracy: 0.9577\n",
      "Epoch 24/30\n",
      "5/5 [==============================] - 0s 72ms/step - loss: 0.0443 - accuracy: 0.9889 - val_loss: 0.0799 - val_accuracy: 0.9577\n",
      "Epoch 25/30\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 0.0462 - accuracy: 0.9795 - val_loss: 0.0910 - val_accuracy: 0.9577\n",
      "Epoch 26/30\n",
      "5/5 [==============================] - 0s 72ms/step - loss: 0.0534 - accuracy: 0.9826 - val_loss: 0.1323 - val_accuracy: 0.9577\n",
      "Epoch 27/30\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0689 - accuracy: 0.9779"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 5-conv-32-layer-1-dense.model_00h/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 5-conv-32-layer-1-dense.model_00h/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 444ms/step - loss: 0.0689 - accuracy: 0.9779 - val_loss: 0.0768 - val_accuracy: 0.9577\n",
      "Epoch 28/30\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 0.0532 - accuracy: 0.9826 - val_loss: 0.1743 - val_accuracy: 0.9296\n",
      "Epoch 29/30\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0681 - accuracy: 0.9826"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 5-conv-32-layer-1-dense.model_00h/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 5-conv-32-layer-1-dense.model_00h/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 509ms/step - loss: 0.0681 - accuracy: 0.9826 - val_loss: 0.0612 - val_accuracy: 0.9437\n",
      "Epoch 30/30\n",
      "5/5 [==============================] - 0s 72ms/step - loss: 0.0404 - accuracy: 0.9889 - val_loss: 0.1141 - val_accuracy: 0.9577\n",
      "--> Running configuration:  3-conv-32-layer-2-dense.model_00h\n",
      "Model: \"my_functional_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_5 (InputLayer)        [(None, 30, 30, 12)]      0         \n",
      "                                                                 \n",
      " sequential (Sequential)     (None, 30, 30, 12)        0         \n",
      "                                                                 \n",
      " my_conv2d_1 (Conv2D)        (None, 28, 28, 32)        3488      \n",
      "                                                                 \n",
      " my_pooling_1 (MaxPooling2D)  (None, 14, 14, 32)       0         \n",
      "                                                                 \n",
      " my_conv2d_2 (Conv2D)        (None, 12, 12, 64)        18496     \n",
      "                                                                 \n",
      " my_pooling_2 (MaxPooling2D)  (None, 6, 6, 64)         0         \n",
      "                                                                 \n",
      " my_conv2d_3 (Conv2D)        (None, 4, 4, 128)         73856     \n",
      "                                                                 \n",
      " my_pooling_3 (MaxPooling2D)  (None, 2, 2, 128)        0         \n",
      "                                                                 \n",
      " my_flatten (Flatten)        (None, 512)               0         \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 32)                16416     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 32)                1056      \n",
      "                                                                 \n",
      " my_dense (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 113,345\n",
      "Trainable params: 113,345\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.6536 - accuracy: 0.6572"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 3-conv-32-layer-2-dense.model_00h/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 3-conv-32-layer-2-dense.model_00h/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 3s 496ms/step - loss: 0.6536 - accuracy: 0.6572 - val_loss: 0.5357 - val_accuracy: 0.8451\n",
      "Epoch 2/30\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.4424 - accuracy: 0.8831"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 3-conv-32-layer-2-dense.model_00h/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 3-conv-32-layer-2-dense.model_00h/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 555ms/step - loss: 0.4424 - accuracy: 0.8831 - val_loss: 0.3393 - val_accuracy: 0.8451\n",
      "Epoch 3/30\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.2678 - accuracy: 0.8768"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 3-conv-32-layer-2-dense.model_00h/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 3-conv-32-layer-2-dense.model_00h/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 471ms/step - loss: 0.2678 - accuracy: 0.8768 - val_loss: 0.2544 - val_accuracy: 0.9155\n",
      "Epoch 4/30\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.2135 - accuracy: 0.9036"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 3-conv-32-layer-2-dense.model_00h/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 3-conv-32-layer-2-dense.model_00h/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 471ms/step - loss: 0.2135 - accuracy: 0.9036 - val_loss: 0.2085 - val_accuracy: 0.9296\n",
      "Epoch 5/30\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.2113 - accuracy: 0.9163"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 3-conv-32-layer-2-dense.model_00h/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 3-conv-32-layer-2-dense.model_00h/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 561ms/step - loss: 0.2113 - accuracy: 0.9163 - val_loss: 0.1662 - val_accuracy: 0.9155\n",
      "Epoch 6/30\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 0.2397 - accuracy: 0.8957 - val_loss: 0.4044 - val_accuracy: 0.8310\n",
      "Epoch 7/30\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.2328 - accuracy: 0.9068"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 3-conv-32-layer-2-dense.model_00h/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 3-conv-32-layer-2-dense.model_00h/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 466ms/step - loss: 0.2328 - accuracy: 0.9068 - val_loss: 0.1584 - val_accuracy: 0.9296\n",
      "Epoch 8/30\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 0.1910 - accuracy: 0.9242 - val_loss: 0.2015 - val_accuracy: 0.9155\n",
      "Epoch 9/30\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.1863 - accuracy: 0.9321"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 3-conv-32-layer-2-dense.model_00h/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 3-conv-32-layer-2-dense.model_00h/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 537ms/step - loss: 0.1863 - accuracy: 0.9321 - val_loss: 0.1513 - val_accuracy: 0.9155\n",
      "Epoch 10/30\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 0.1487 - accuracy: 0.9400 - val_loss: 0.1762 - val_accuracy: 0.9296\n",
      "Epoch 11/30\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.1235 - accuracy: 0.9558"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 3-conv-32-layer-2-dense.model_00h/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 3-conv-32-layer-2-dense.model_00h/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 475ms/step - loss: 0.1235 - accuracy: 0.9558 - val_loss: 0.1245 - val_accuracy: 0.9296\n",
      "Epoch 12/30\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 0.1127 - accuracy: 0.9589 - val_loss: 0.1625 - val_accuracy: 0.9155\n",
      "Epoch 13/30\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.1136 - accuracy: 0.9542"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 3-conv-32-layer-2-dense.model_00h/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 3-conv-32-layer-2-dense.model_00h/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 534ms/step - loss: 0.1136 - accuracy: 0.9542 - val_loss: 0.1191 - val_accuracy: 0.9437\n",
      "Epoch 14/30\n",
      "5/5 [==============================] - 0s 76ms/step - loss: 0.0964 - accuracy: 0.9573 - val_loss: 0.1647 - val_accuracy: 0.9155\n",
      "Epoch 15/30\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0938 - accuracy: 0.9637"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 3-conv-32-layer-2-dense.model_00h/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 3-conv-32-layer-2-dense.model_00h/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 486ms/step - loss: 0.0938 - accuracy: 0.9637 - val_loss: 0.1100 - val_accuracy: 0.9437\n",
      "Epoch 16/30\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 0.0717 - accuracy: 0.9731 - val_loss: 0.1684 - val_accuracy: 0.9155\n",
      "Epoch 17/30\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 0.0810 - accuracy: 0.9652 - val_loss: 0.1121 - val_accuracy: 0.9437\n",
      "Epoch 18/30\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 0.0768 - accuracy: 0.9716 - val_loss: 0.1798 - val_accuracy: 0.9296\n",
      "Epoch 19/30\n",
      "5/5 [==============================] - 0s 76ms/step - loss: 0.0688 - accuracy: 0.9795 - val_loss: 0.1206 - val_accuracy: 0.9437\n",
      "Epoch 20/30\n",
      "5/5 [==============================] - 0s 72ms/step - loss: 0.0662 - accuracy: 0.9747 - val_loss: 0.1330 - val_accuracy: 0.9437\n",
      "Epoch 21/30\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0394 - accuracy: 0.9858"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 3-conv-32-layer-2-dense.model_00h/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 3-conv-32-layer-2-dense.model_00h/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 474ms/step - loss: 0.0394 - accuracy: 0.9858 - val_loss: 0.1073 - val_accuracy: 0.9437\n",
      "Epoch 22/30\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 0.0628 - accuracy: 0.9763 - val_loss: 0.1181 - val_accuracy: 0.9437\n",
      "Epoch 23/30\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 0.0546 - accuracy: 0.9810 - val_loss: 0.1205 - val_accuracy: 0.9437\n",
      "Epoch 24/30\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 0.0375 - accuracy: 0.9874 - val_loss: 0.1163 - val_accuracy: 0.9437\n",
      "Epoch 25/30\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 0.0446 - accuracy: 0.9874 - val_loss: 0.1286 - val_accuracy: 0.9437\n",
      "Epoch 26/30\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 0.0403 - accuracy: 0.9842 - val_loss: 0.1093 - val_accuracy: 0.9437\n",
      "Epoch 27/30\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 0.0595 - accuracy: 0.9810 - val_loss: 0.1101 - val_accuracy: 0.9437\n",
      "Epoch 28/30\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 0.0313 - accuracy: 0.9874 - val_loss: 0.1915 - val_accuracy: 0.9577\n",
      "Epoch 29/30\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 0.0414 - accuracy: 0.9842 - val_loss: 0.1350 - val_accuracy: 0.9577\n",
      "Epoch 30/30\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0296 - accuracy: 0.9889"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 3-conv-32-layer-2-dense.model_00h/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 3-conv-32-layer-2-dense.model_00h/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 572ms/step - loss: 0.0296 - accuracy: 0.9889 - val_loss: 0.1024 - val_accuracy: 0.9437\n",
      "--> Running configuration:  5-conv-32-layer-2-dense.model_00h\n",
      "Model: \"my_functional_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_6 (InputLayer)        [(None, 30, 30, 12)]      0         \n",
      "                                                                 \n",
      " sequential (Sequential)     (None, 30, 30, 12)        0         \n",
      "                                                                 \n",
      " my_conv2d_1 (Conv2D)        (None, 26, 26, 32)        9632      \n",
      "                                                                 \n",
      " my_pooling_1 (MaxPooling2D)  (None, 13, 13, 32)       0         \n",
      "                                                                 \n",
      " my_conv2d_2 (Conv2D)        (None, 9, 9, 64)          51264     \n",
      "                                                                 \n",
      " my_pooling_2 (MaxPooling2D)  (None, 4, 4, 64)         0         \n",
      "                                                                 \n",
      " my_flatten (Flatten)        (None, 1024)              0         \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 32)                32800     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 32)                1056      \n",
      "                                                                 \n",
      " my_dense (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 94,785\n",
      "Trainable params: 94,785\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.6384 - accuracy: 0.6825"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 5-conv-32-layer-2-dense.model_00h/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 5-conv-32-layer-2-dense.model_00h/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 3s 547ms/step - loss: 0.6384 - accuracy: 0.6825 - val_loss: 0.4719 - val_accuracy: 0.8169\n",
      "Epoch 2/30\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.3845 - accuracy: 0.8894"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 5-conv-32-layer-2-dense.model_00h/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 5-conv-32-layer-2-dense.model_00h/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 447ms/step - loss: 0.3845 - accuracy: 0.8894 - val_loss: 0.2243 - val_accuracy: 0.9296\n",
      "Epoch 3/30\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.2489 - accuracy: 0.8989"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 5-conv-32-layer-2-dense.model_00h/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 5-conv-32-layer-2-dense.model_00h/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 447ms/step - loss: 0.2489 - accuracy: 0.8989 - val_loss: 0.1675 - val_accuracy: 0.9155\n",
      "Epoch 4/30\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 0.1985 - accuracy: 0.9210 - val_loss: 0.2016 - val_accuracy: 0.9014\n",
      "Epoch 5/30\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 0.2066 - accuracy: 0.9131 - val_loss: 0.1837 - val_accuracy: 0.9437\n",
      "Epoch 6/30\n",
      "5/5 [==============================] - 0s 76ms/step - loss: 0.1779 - accuracy: 0.9305 - val_loss: 0.1823 - val_accuracy: 0.9014\n",
      "Epoch 7/30\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.1462 - accuracy: 0.9384"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 5-conv-32-layer-2-dense.model_00h/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 5-conv-32-layer-2-dense.model_00h/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 543ms/step - loss: 0.1462 - accuracy: 0.9384 - val_loss: 0.1282 - val_accuracy: 0.9437\n",
      "Epoch 8/30\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 0.1348 - accuracy: 0.9558 - val_loss: 0.1503 - val_accuracy: 0.9437\n",
      "Epoch 9/30\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.1255 - accuracy: 0.9510"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 5-conv-32-layer-2-dense.model_00h/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 5-conv-32-layer-2-dense.model_00h/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 446ms/step - loss: 0.1255 - accuracy: 0.9510 - val_loss: 0.1046 - val_accuracy: 0.9577\n",
      "Epoch 10/30\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.1023 - accuracy: 0.9573"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 5-conv-32-layer-2-dense.model_00h/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 5-conv-32-layer-2-dense.model_00h/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 446ms/step - loss: 0.1023 - accuracy: 0.9573 - val_loss: 0.0978 - val_accuracy: 0.9577\n",
      "Epoch 11/30\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 0.1210 - accuracy: 0.9494 - val_loss: 0.1185 - val_accuracy: 0.9437\n",
      "Epoch 12/30\n",
      "5/5 [==============================] - 0s 76ms/step - loss: 0.0930 - accuracy: 0.9731 - val_loss: 0.1106 - val_accuracy: 0.9577\n",
      "Epoch 13/30\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 0.0823 - accuracy: 0.9652 - val_loss: 0.0996 - val_accuracy: 0.9577\n",
      "Epoch 14/30\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 0.0852 - accuracy: 0.9684 - val_loss: 0.1378 - val_accuracy: 0.9437\n",
      "Epoch 15/30\n",
      "5/5 [==============================] - 0s 76ms/step - loss: 0.0790 - accuracy: 0.9684 - val_loss: 0.1071 - val_accuracy: 0.9437\n",
      "Epoch 16/30\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0671 - accuracy: 0.9763"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 5-conv-32-layer-2-dense.model_00h/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 5-conv-32-layer-2-dense.model_00h/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 526ms/step - loss: 0.0671 - accuracy: 0.9763 - val_loss: 0.0939 - val_accuracy: 0.9437\n",
      "Epoch 17/30\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 0.0730 - accuracy: 0.9795 - val_loss: 0.1057 - val_accuracy: 0.9577\n",
      "Epoch 18/30\n",
      "5/5 [==============================] - 0s 76ms/step - loss: 0.0631 - accuracy: 0.9810 - val_loss: 0.0960 - val_accuracy: 0.9437\n",
      "Epoch 19/30\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 0.0691 - accuracy: 0.9763 - val_loss: 0.0972 - val_accuracy: 0.9437\n",
      "Epoch 20/30\n",
      "5/5 [==============================] - 0s 76ms/step - loss: 0.0491 - accuracy: 0.9810 - val_loss: 0.1143 - val_accuracy: 0.9577\n",
      "Epoch 21/30\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0503 - accuracy: 0.9842"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 5-conv-32-layer-2-dense.model_00h/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 5-conv-32-layer-2-dense.model_00h/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 445ms/step - loss: 0.0503 - accuracy: 0.9842 - val_loss: 0.0910 - val_accuracy: 0.9437\n",
      "Epoch 22/30\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 0.0518 - accuracy: 0.9795 - val_loss: 0.0977 - val_accuracy: 0.9437\n",
      "Epoch 23/30\n",
      "5/5 [==============================] - 0s 76ms/step - loss: 0.0528 - accuracy: 0.9747 - val_loss: 0.1544 - val_accuracy: 0.9437\n",
      "Epoch 24/30\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0493 - accuracy: 0.9810"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 5-conv-32-layer-2-dense.model_00h/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 5-conv-32-layer-2-dense.model_00h/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 531ms/step - loss: 0.0493 - accuracy: 0.9810 - val_loss: 0.0852 - val_accuracy: 0.9437\n",
      "Epoch 25/30\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0455 - accuracy: 0.9826"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 5-conv-32-layer-2-dense.model_00h/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 5-conv-32-layer-2-dense.model_00h/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 454ms/step - loss: 0.0455 - accuracy: 0.9826 - val_loss: 0.0785 - val_accuracy: 0.9718\n",
      "Epoch 26/30\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 0.0557 - accuracy: 0.9795 - val_loss: 0.0967 - val_accuracy: 0.9577\n",
      "Epoch 27/30\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 0.0430 - accuracy: 0.9779 - val_loss: 0.1352 - val_accuracy: 0.9437\n",
      "Epoch 28/30\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 0.0393 - accuracy: 0.9858 - val_loss: 0.0798 - val_accuracy: 0.9859\n",
      "Epoch 29/30\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0593 - accuracy: 0.9731"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 5-conv-32-layer-2-dense.model_00h/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 5-conv-32-layer-2-dense.model_00h/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 437ms/step - loss: 0.0593 - accuracy: 0.9731 - val_loss: 0.0713 - val_accuracy: 0.9577\n",
      "Epoch 30/30\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 0.0883 - accuracy: 0.9605 - val_loss: 0.1550 - val_accuracy: 0.9437\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# build a range of CNN models with different number of dense layer, layer sizes, and\n",
    "# convolution layers to optimize the performance\n",
    "#\n",
    "data_augmentation = keras.Sequential([\n",
    "    layers.RandomFlip(\"horizontal\"),\n",
    "    layers.RandomRotation(0.1),\n",
    "    layers.RandomZoom(0.2)])\n",
    "dense_layers = [0, 1, 2]\n",
    "layer_sizes = [32]\n",
    "conv_layers = [3, 5]\n",
    "for dense_layer in dense_layers:\n",
    "    for layer_size in layer_sizes:\n",
    "        for conv_layer in conv_layers:\n",
    "            NAME = \"{}-conv-{}-layer-{}-dense.model_00h\".format(conv_layer, layer_size, dense_layer)\n",
    "            print('--> Running configuration: ',NAME)\n",
    "\n",
    "            inputs = keras.Input(shape=X.shape[1:])      \n",
    "            x = data_augmentation(inputs)\n",
    "            x = layers.Conv2D(filters=layer_size,kernel_size=conv_layer,activation=\"relu\",name=\"my_conv2d_1\")(x)\n",
    "            x = layers.MaxPooling2D(pool_size=2,name=\"my_pooling_1\")(x)\n",
    "            x = layers.Conv2D(filters=layer_size*2,kernel_size=conv_layer,activation=\"relu\",name=\"my_conv2d_2\")(x)\n",
    "            x = layers.MaxPooling2D(pool_size=2,name=\"my_pooling_2\")(x)\n",
    "            if conv_layer == 3:\n",
    "                x = layers.Conv2D(filters=layer_size*4,kernel_size=conv_layer,activation=\"relu\",name=\"my_conv2d_3\")(x)\n",
    "                x = layers.MaxPooling2D(pool_size=2,name=\"my_pooling_3\")(x)\n",
    "\n",
    "            if X.shape[1] > 128:\n",
    "                x = layers.Conv2D(filters=256,kernel_size=conv_layer,activation=\"relu\",name=\"my_conv2d_4\")(x)\n",
    "                x = layers.MaxPooling2D(pool_size=2,name=\"my_pooling_4\")(x)\n",
    "                x = layers.Conv2D(filters=256,kernel_size=conv_layer,activation=\"relu\",name=\"my_conv2d_5\")(x)\n",
    "            x = layers.Flatten(name=\"my_flatten\")(x)\n",
    "            x = layers.Dropout(0.2)(x)\n",
    "            \n",
    "            for _ in range(dense_layer):\n",
    "                x = layers.Dense(layer_size,activation=\"relu\")(x)                \n",
    "                \n",
    "            outputs = layers.Dense(1,activation=\"sigmoid\",name=\"my_dense\")(x)\n",
    "            model = keras.Model(inputs=inputs,outputs=outputs,name=\"my_functional_model\")\n",
    "            model.summary()\n",
    "            keras.utils.plot_model(model)\n",
    "            \n",
    "            callbacks=[keras.callbacks.ModelCheckpoint(NAME,save_best_only=True)]\n",
    "            model.compile(loss=\"binary_crossentropy\",optimizer=\"adam\",metrics=[\"accuracy\"])\n",
    "            history = model.fit(X, y, batch_size=128, epochs=30, validation_split=0.1, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6cf3621",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#\n",
    "# Visualize the output of the training model (work for jupyter notebook only)\n",
    "#\n",
    "import matplotlib.pyplot as plt\n",
    "check_visualization = \"yes\"\n",
    "if check_visualization== \"yes\":\n",
    "    #print(history.__dict__)\n",
    "    #print(history.history)\n",
    "    val_accuracy = history.history['val_accuracy']\n",
    "    accuracy = history.history['accuracy']\n",
    "    epochs = history.epoch \n",
    "    plt.plot(epochs,val_accuracy,'r',label=\"val accuracy\")\n",
    "    plt.plot(epochs,accuracy,'b',label=\"train accuracy\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.figure()\n",
    "    val_loss = history.history['val_loss']\n",
    "    loss = history.history['loss']\n",
    "    plt.plot(epochs,val_loss,'r',label=\"val loss\")\n",
    "    plt.plot(epochs,loss,'b',label=\"train loss\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4f679c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
