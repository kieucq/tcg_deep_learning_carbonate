{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80518cb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-20 14:46:14.660546: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# NOTE: This machine learning program is for predicting TC formation, using\n",
    "#       input dataset in the NETCDF format. The program treats different\n",
    "#       2D input fields as different channels of an image. This specific\n",
    "#       program requires a set of 12 2D-variables (12-channel image) and\n",
    "#       consists of three stages\n",
    "#       - Stage 1: reading NETCDF input and generating (X,y) data with a\n",
    "#                  given image sizes, which are then saved by pickle;\n",
    "#       - Stage 2: import the saved pickle (X,y) pair and build a CNN model\n",
    "#                  with a given training/validation ratio, and then save\n",
    "#                  the train model under tcg_CNN.model.\n",
    "#       - Stage 3: import the trained model from Stage 2, and make a list\n",
    "#                  of prediction from normalized test data.\n",
    "#\n",
    "# INPUT: This Stage 3 script reads in the CNN trained model \"tcg_CNN.model\"\n",
    "#        that is generated from Step 2.\n",
    "#\n",
    "#        Remarks: Note that the input data for this script must be on the\n",
    "#        same as in Step 1 with standard 19 vertical\n",
    "#        levels 1000, 975, 950, 925, 900, 850, 800, 750, 700, 650, 600,\n",
    "#        550, 500, 450, 400, 350, 300, 250, 200. Also, all field vars must\n",
    "#        be resize to cover an area of 30x30 around the TC center for the\n",
    "#        positive data cases.\n",
    "#        Similar to Step 2, this Step 3 needs to also have a large mem\n",
    "#        allocation so that it can be run properly.\n",
    "#\n",
    "# OUTPUT: A list of probability forecast with the same dimension as the\n",
    "#        number of input 12-channel images.\n",
    "#\n",
    "# HIST: - 01, Nov 22: Created by CK\n",
    "#       - 02, Nov 22: Modified to optimize it\n",
    "#       - 05. Jun 23: Rechecked and added F1 score function for a list of models\n",
    "#\n",
    "# AUTH: Chanh Kieu (Indiana University, Bloomington. Email: ckieu@iu.edu)\n",
    "#\n",
    "#==========================================================================\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import netCDF4\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70d857fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Function to return input data as an numpy array\n",
    "#\n",
    "def prepare(filepath):\n",
    "    IMG_SIZE = 30\n",
    "    number_channels = 12\n",
    "    f = netCDF4.Dataset(filepath)\n",
    "    abv = f.variables['absvprs']\n",
    "    nx = np.size(abv[0,0,:])\n",
    "    ny = np.size(abv[0,:,0])\n",
    "    nz = np.size(abv[:,0,0])\n",
    "    #print('Dimension of input NETCDF is: ',nx,ny,nz)\n",
    "    a2 = np.zeros((nx,ny,number_channels))\n",
    "    for i in range(a2.shape[0]):\n",
    "        for j in range(a2.shape[1]):\n",
    "            a2[i,j,0] = abv[1,j,i]    # abs vort at 950 mb\n",
    "    rel = f.variables['rhprs']\n",
    "    for i in range(a2.shape[0]):\n",
    "        for j in range(a2.shape[1]):\n",
    "            a2[i,j,1] = rel[7,j,i]    # RH at 750 mb\n",
    "    sfc = f.variables['pressfc']\n",
    "    for i in range(a2.shape[0]):\n",
    "        for j in range(a2.shape[1]):\n",
    "            a2[i,j,2] = sfc[j,i]      # surface pressure\n",
    "    tmp = f.variables['tmpprs']\n",
    "    for i in range(a2.shape[0]):\n",
    "        for j in range(a2.shape[1]):\n",
    "            a2[i,j,3] = tmp[15,j,i]   # temperature at 400 mb\n",
    "    tsf = f.variables['tmpsfc']\n",
    "    for i in range(a2.shape[0]):\n",
    "        for j in range(a2.shape[1]):\n",
    "            a2[i,j,4] = tsf[j,i]      # surface temperature\n",
    "    ugr = f.variables['ugrdprs']\n",
    "    for i in range(a2.shape[0]):\n",
    "        for j in range(a2.shape[1]):\n",
    "            a2[i,j,5] = ugr[3,j,i]    # u-wind at 900 mb\n",
    "            a2[i,j,6] = ugr[17,j,i]   # u-wind at 300 mb\n",
    "    vgr = f.variables['vgrdprs']\n",
    "    for i in range(a2.shape[0]):\n",
    "        for j in range(a2.shape[1]):\n",
    "            a2[i,j,7] = vgr[3,j,i]    # v-wind at 900 mb\n",
    "            a2[i,j,8] = vgr[17,j,i]   # v-wind at 300 mb\n",
    "    hgt = f.variables['hgtprs']\n",
    "    for i in range(a2.shape[0]):\n",
    "        for j in range(a2.shape[1]):\n",
    "            a2[i,j,9] = hgt[3,j,i]    # geopotential at 850 mb\n",
    "    wgr = f.variables['vvelprs']\n",
    "    for i in range(a2.shape[0]):\n",
    "        for j in range(a2.shape[1]):\n",
    "            a2[i,j,10] = wgr[3,j,i]   # w-wind at 900 mb\n",
    "            a2[i,j,11] = wgr[17,j,i]  # w-wind at 300 mb\n",
    "    new_array = cv2.resize(a2, (IMG_SIZE, IMG_SIZE))\n",
    "    #\n",
    "    # normalize the data\n",
    "    #\n",
    "    #print('Number of channels to normalize is: ',number_channels)\n",
    "    for var in range(number_channels):\n",
    "        maxvalue = new_array[:,:,var].flat[np.abs(new_array[:,:,var]).argmax()]\n",
    "        #print('Normalization factor for channel',var,', is: ',abs(maxvalue))\n",
    "        new_array[:,:,var] = new_array[:,:,var]/abs(maxvalue)\n",
    "    out_array = np.reshape(new_array, (-1, IMG_SIZE, IMG_SIZE, number_channels))\n",
    "    #print('reshape new_array returns: ',out_array.shape)\n",
    "    #input('Enter to continue...')\n",
    "    return out_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4354361",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# build an F1-score function for later use\n",
    "#\n",
    "def F1_score(y_true,y_prediction,true_class,true_threshold):\n",
    "    T = len(y_true)\n",
    "    if len(y_prediction) != T:\n",
    "        print(\"Prediction and true label arrays have different size. Stop\")\n",
    "        return\n",
    "    P = 0\n",
    "    TP = 0 \n",
    "    FN = 0\n",
    "    TN = 0\n",
    "    FP = 0\n",
    "    for i in range(T):\n",
    "        if y_true[i] == true_class:\n",
    "            P = P + 1       \n",
    "            if y_prediction[i] >= true_threshold:\n",
    "                TP += 1 \n",
    "            else:\n",
    "                FN += 1\n",
    "        else:\n",
    "            if y_prediction[i] >= true_threshold:\n",
    "                FP += 1 \n",
    "            else:\n",
    "                TN += 1            \n",
    "    N = T - P    \n",
    "    F1 = 2.*TP/(2.*TP + FP + FN)\n",
    "    Recall = TP/float(TP+FN)\n",
    "    if TP == 0 and FP == 0: \n",
    "        Precision = 0.\n",
    "    else:    \n",
    "        Precision = TP/float(TP+FP)\n",
    "    return F1, Recall, Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2815a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-20 14:46:47.065800: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-20 14:46:47.682692: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 104 MB memory:  -> device: 0, name: Tesla V100-PCIE-32GB, pci bus id: 0000:b1:00.0, compute capability: 7.0\n",
      "2023-06-20 14:46:47.701238: I tensorflow/stream_executor/cuda/cuda_driver.cc:739] failed to allocate 104.44M (109510656 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "  0%|                                                                                                                                                                  | 0/54 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: /N/slate/ckieu/deep-learning/data/ncep_binary_30x30_00h/testing/neg/20210717_00_00_20.5_183.5.nc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-20 14:46:50.875348: E tensorflow/stream_executor/cuda/cuda_dnn.cc:389] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR\n",
      "2023-06-20 14:46:50.875852: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at conv_ops.cc:1120 : UNIMPLEMENTED: DNN library is not found.\n",
      "  2%|██▊                                                                                                                                                       | 1/54 [00:06<05:26,  6.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: /N/slate/ckieu/deep-learning/data/ncep_binary_30x30_00h/testing/neg/20210728_06_00_11.7_307.5.nc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-20 14:47:01.048344: E tensorflow/stream_executor/cuda/cuda_dnn.cc:389] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR\n",
      "2023-06-20 14:47:01.048768: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at conv_ops.cc:1120 : UNIMPLEMENTED: DNN library is not found.\n",
      "\r",
      "  4%|█████▋                                                                                                                                                    | 2/54 [00:12<05:21,  6.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: /N/slate/ckieu/deep-learning/data/ncep_binary_30x30_00h/testing/neg/20210830_00_00_58.2_348.5.nc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-20 14:47:03.620083: E tensorflow/stream_executor/cuda/cuda_dnn.cc:389] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR\n",
      "2023-06-20 14:47:03.621005: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at conv_ops.cc:1120 : UNIMPLEMENTED: DNN library is not found.\n",
      "\r",
      "  6%|████████▌                                                                                                                                                 | 3/54 [00:14<03:51,  4.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: /N/slate/ckieu/deep-learning/data/ncep_binary_30x30_00h/testing/neg/20210705_00_00_18.2_175.3.nc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-20 14:47:06.185654: E tensorflow/stream_executor/cuda/cuda_dnn.cc:389] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR\n",
      "2023-06-20 14:47:06.186042: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at conv_ops.cc:1120 : UNIMPLEMENTED: DNN library is not found.\n",
      "\r",
      "  7%|███████████▍                                                                                                                                              | 4/54 [00:17<03:07,  3.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: /N/slate/ckieu/deep-learning/data/ncep_binary_30x30_00h/testing/neg/20210805_00_00_31.6_197.4.nc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-20 14:47:08.757125: E tensorflow/stream_executor/cuda/cuda_dnn.cc:389] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR\n",
      "2023-06-20 14:47:08.757469: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at conv_ops.cc:1120 : UNIMPLEMENTED: DNN library is not found.\n",
      "\r",
      "  9%|██████████████▎                                                                                                                                           | 5/54 [00:20<02:43,  3.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: /N/slate/ckieu/deep-learning/data/ncep_binary_30x30_00h/testing/neg/20210519_00_00_-5.2_266.3.nc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-20 14:47:11.322115: E tensorflow/stream_executor/cuda/cuda_dnn.cc:389] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR\n",
      "2023-06-20 14:47:11.322510: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at conv_ops.cc:1120 : UNIMPLEMENTED: DNN library is not found.\n",
      "\r",
      " 11%|█████████████████                                                                                                                                         | 6/54 [00:22<02:27,  3.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: /N/slate/ckieu/deep-learning/data/ncep_binary_30x30_00h/testing/neg/20210612_00_00_18.2_160.0.nc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-20 14:47:13.890216: E tensorflow/stream_executor/cuda/cuda_dnn.cc:389] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR\n",
      "2023-06-20 14:47:13.890593: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at conv_ops.cc:1120 : UNIMPLEMENTED: DNN library is not found.\n",
      "\r",
      " 13%|███████████████████▉                                                                                                                                      | 7/54 [00:25<02:16,  2.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: /N/slate/ckieu/deep-learning/data/ncep_binary_30x30_00h/testing/neg/20210728_00_00_32.6_167.8.nc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-20 14:47:16.460259: E tensorflow/stream_executor/cuda/cuda_dnn.cc:389] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR\n",
      "2023-06-20 14:47:16.460571: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at conv_ops.cc:1120 : UNIMPLEMENTED: DNN library is not found.\n",
      "\r",
      " 15%|██████████████████████▊                                                                                                                                   | 8/54 [00:27<02:08,  2.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: /N/slate/ckieu/deep-learning/data/ncep_binary_30x30_00h/testing/neg/20210914_00_00_22.7_341.4.nc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-20 14:47:19.033601: E tensorflow/stream_executor/cuda/cuda_dnn.cc:389] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR\n",
      "2023-06-20 14:47:19.033968: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at conv_ops.cc:1120 : UNIMPLEMENTED: DNN library is not found.\n",
      "\r",
      " 17%|█████████████████████████▋                                                                                                                                | 9/54 [00:30<02:02,  2.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: /N/slate/ckieu/deep-learning/data/ncep_binary_30x30_00h/testing/neg/20210904_12_00_12.6_310.7.nc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-20 14:47:21.602157: E tensorflow/stream_executor/cuda/cuda_dnn.cc:389] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR\n",
      "2023-06-20 14:47:21.602782: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at conv_ops.cc:1120 : UNIMPLEMENTED: DNN library is not found.\n",
      "\r",
      " 19%|████████████████████████████▎                                                                                                                            | 10/54 [00:32<01:57,  2.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: /N/slate/ckieu/deep-learning/data/ncep_binary_30x30_00h/testing/neg/20210916_18_00_62.0_340.5.nc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-20 14:47:24.168033: E tensorflow/stream_executor/cuda/cuda_dnn.cc:389] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR\n",
      "2023-06-20 14:47:24.168398: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at conv_ops.cc:1120 : UNIMPLEMENTED: DNN library is not found.\n",
      "\r",
      " 20%|███████████████████████████████▏                                                                                                                         | 11/54 [00:35<01:53,  2.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: /N/slate/ckieu/deep-learning/data/ncep_binary_30x30_00h/testing/neg/20210922_18_00_11.8_197.5.nc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-20 14:47:26.744983: E tensorflow/stream_executor/cuda/cuda_dnn.cc:389] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR\n",
      "2023-06-20 14:47:26.745448: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at conv_ops.cc:1120 : UNIMPLEMENTED: DNN library is not found.\n",
      "\r",
      " 22%|██████████████████████████████████                                                                                                                       | 12/54 [00:38<01:50,  2.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: /N/slate/ckieu/deep-learning/data/ncep_binary_30x30_00h/testing/neg/20210621_00_00_11.2_197.4.nc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-20 14:47:29.308228: E tensorflow/stream_executor/cuda/cuda_dnn.cc:389] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR\n",
      "2023-06-20 14:47:29.308635: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at conv_ops.cc:1120 : UNIMPLEMENTED: DNN library is not found.\n",
      "\r",
      " 24%|████████████████████████████████████▊                                                                                                                    | 13/54 [00:40<01:46,  2.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: /N/slate/ckieu/deep-learning/data/ncep_binary_30x30_00h/testing/neg/20210806_12_00_15.0_308.0.nc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-20 14:47:31.878787: E tensorflow/stream_executor/cuda/cuda_dnn.cc:389] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR\n",
      "2023-06-20 14:47:31.879210: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at conv_ops.cc:1120 : UNIMPLEMENTED: DNN library is not found.\n",
      "\r",
      " 26%|███████████████████████████████████████▋                                                                                                                 | 14/54 [00:43<01:43,  2.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: /N/slate/ckieu/deep-learning/data/ncep_binary_30x30_00h/testing/neg/20210929_00_00_57.0_338.0.nc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-20 14:47:34.451226: E tensorflow/stream_executor/cuda/cuda_dnn.cc:389] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR\n",
      "2023-06-20 14:47:34.451602: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at conv_ops.cc:1120 : UNIMPLEMENTED: DNN library is not found.\n",
      "\r",
      " 28%|██████████████████████████████████████████▌                                                                                                              | 15/54 [00:45<01:40,  2.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: /N/slate/ckieu/deep-learning/data/ncep_binary_30x30_00h/testing/neg/20210508_12_00_12.7_304.4.nc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-20 14:47:37.013892: E tensorflow/stream_executor/cuda/cuda_dnn.cc:389] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR\n",
      "2023-06-20 14:47:37.014262: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at conv_ops.cc:1120 : UNIMPLEMENTED: DNN library is not found.\n",
      "\r",
      " 30%|█████████████████████████████████████████████▎                                                                                                           | 16/54 [00:48<01:38,  2.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: /N/slate/ckieu/deep-learning/data/ncep_binary_30x30_00h/testing/neg/20210906_06_00_14.0_188.3.nc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-20 14:47:39.582177: E tensorflow/stream_executor/cuda/cuda_dnn.cc:389] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR\n",
      "2023-06-20 14:47:39.582515: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at conv_ops.cc:1120 : UNIMPLEMENTED: DNN library is not found.\n",
      "\r",
      " 31%|████████████████████████████████████████████████▏                                                                                                        | 17/54 [00:50<01:35,  2.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: /N/slate/ckieu/deep-learning/data/ncep_binary_30x30_00h/testing/neg/20210923_12_00_62.7_336.6.nc\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# loop thru all best-saved CNN trained models and make a prediction. Note that prediction is applied one by one instead \n",
    "# of a batch input. \n",
    "#\n",
    "DATADIR = \"/N/slate/ckieu/deep-learning/data/ncep_binary_30x30_00h/testing\"\n",
    "bestmodels = [\"3-conv-32-layer-0-dense.model_00h\",\"3-conv-32-layer-1-dense.model_00h\",\"3-conv-32-layer-2-dense.model_00h\",\n",
    "              \"5-conv-32-layer-0-dense.model_00h\",\"5-conv-32-layer-1-dense.model_00h\",\"5-conv-32-layer-2-dense.model_00h\"]\n",
    "CATEGORIES = [\"neg\", \"pos\"]\n",
    "F1_performance = []\n",
    "for bestmodel in bestmodels:\n",
    "    model = tf.keras.models.load_model(bestmodel)\n",
    "    prediction_total = 0\n",
    "    prediction_yes = 0\n",
    "    prediction_history = []\n",
    "    truth_history = []\n",
    "    for category in CATEGORIES:\n",
    "        path = os.path.join(DATADIR,category)\n",
    "        for img in tqdm(os.listdir(path)):    \n",
    "            try:\n",
    "                img_dir = DATADIR + '/' + category + '/' + img\n",
    "                print('Processing image:', img_dir)\n",
    "                #print('Input image dimension is: ',prepare(img_dir).shape)\n",
    "                prediction = model.predict([prepare(img_dir)])\n",
    "                print(\"TC formation prediction is\",prediction,round(prediction[0][0]),CATEGORIES[round(prediction[0][0])])\n",
    "                prediction_history.append(prediction[0][0])\n",
    "                if round(prediction[0][0]) == 1:\n",
    "                    prediction_yes += 1\n",
    "                if category == \"pos\":\n",
    "                    truth_history.append(1)\n",
    "                else:\n",
    "                    truth_history.append(0)\n",
    "                prediction_total += 1    \n",
    "                if prediction_total > 1000:\n",
    "                    break\n",
    "            except Exception as e:\n",
    "                pass   \n",
    "    #print(f\"Quick check of prediction accuracy for yes event only is: {prediction_yes/prediction_total: .4f}\") \n",
    "    #\n",
    "    # Compute F1 score for each best model now\n",
    "    #\n",
    "    print(prediction_history)\n",
    "    F1_performance.append([bestmodel,F1_score(truth_history,prediction_history,1,0.5)]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c80549e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Print out the F1 performance of all models\n",
    "#\n",
    "print(\"========================================\")\n",
    "print(\"Summary of the CNN model performance:\")\n",
    "for i in range(len(bestmodels)):\n",
    "    print(\"Model:\",F1_performance[i][0],\" --- F1, Recall, Presision:\",np.round(F1_performance[i][1],2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
